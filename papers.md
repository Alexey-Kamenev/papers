# Papers

## 2020-10

[The Efficiency Misnomer](https://arxiv.org/abs/2110.12894)
<details>
<summary>Short abstract</summary>
Model efficiency is a critical aspect of developing and deploying machine learning models.
</details>
<details>
<summary>Notes</summary>
</details>

[Stochastic Training is Not Necessary for Generalization](https://arxiv.org/abs/2109.14119)
<details>
<summary>Short abstract</summary>
It is widely believed that the implicit regularization of stochastic gradient descent (SGD) is fundamental to the impressive generalization behavior we observe in neural networks. In this work, we demonstrate that non-stochastic full-batch training can achieve strong performance on CIFAR-10 that is on-par with SGD, using modern architectures in settings with and without data augmentation.
</details>
